# LLM Provider Configuration
# Options: ollama, groq, openai
LLM_PROVIDER=ollama

# Ollama (default - local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Groq (cloud fallback)
GROQ_API_KEY=your_groq_api_key_here

# OpenAI (optional)
OPENAI_API_KEY=your_openai_api_key_here

# Django
DEBUG=True
SECRET_KEY=your-secret-key-change-in-production
